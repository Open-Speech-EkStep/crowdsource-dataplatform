{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from pandas import ExcelWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'Hindi'\n",
    "english_col = 'English copy'\n",
    "allowed_values = ['x','y','z']\n",
    "languages = [('hi','Hindi')]\n",
    "# ,('gu','Gujarati'),('ta','Tamil'),\n",
    "#                ('bn','Bengali'),('te','Telugu'),('pa','Punjabi'),\n",
    "#                ('mr','Marathi'),('as','Assamese'),('ml','Malayalam'),\n",
    "#                ('or','Odia'),('kn','Kannada')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInputJsonAsDf(input_json_file):\n",
    "    with open(input_json_file) as f:\n",
    "                js = json.load(f)\n",
    "\n",
    "    out_df = pd.DataFrame(list(js.items()),\n",
    "                       columns=['Key', 'value'])        \n",
    "    out_df['Key_lower'] = out_df['Key'].str.lower()\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(df_row):\n",
    "    if not(pd.notnull(df_row[lang])):\n",
    "        pass\n",
    "    else:\n",
    "        df_row['value'] = df_row[lang]\n",
    "    return df_row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(df_row):\n",
    "    for value in allowed_values:\n",
    "        try:\n",
    "            if pd.notna(df_row[value]):\n",
    "                df_row[lang] = df_row[lang].replace('<'+ value + '>', df_row[value])\n",
    "                df_row['key'] = df_row['key'].replace('<'+ value + '>', df_row[value])\n",
    "        except:\n",
    "            pass\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(json_obj):\n",
    "    json_dict = {}\n",
    "    for key, value in json_obj:\n",
    "        json_dict[key] = value\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_xls(list_dfs, xls_path):\n",
    "    with ExcelWriter(xls_path) as writer:\n",
    "        for n, df in enumerate(list_dfs):\n",
    "            df.to_excel(writer,languages[n][1])\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTranslationFromSheets(locale, translation_excel_files):\n",
    "    excelDf = pd.DataFrame([], columns=['Key', lang])\n",
    "    for excel_file_name in translation_excel_files:\n",
    "#         print(\"---------------\",excel_file_name, \"------------------\")\n",
    "        excel = pd.ExcelFile(locale + '/' + excel_file_name)\n",
    "\n",
    "        count = 0\n",
    "        for sheetName in excel.sheet_names:\n",
    "            sheet = excel.parse(sheet_name = sheetName, header=1)\n",
    "            if(len(sheet.columns) == 0):\n",
    "                continue\n",
    "#             print(sheetName, sheet.columns)\n",
    "            FORMAT = [english_col,lang]\n",
    "            for value in allowed_values:\n",
    "                if value in sheet.columns:\n",
    "                    FORMAT.append(value)\n",
    "            filteredSheet = sheet[FORMAT]\n",
    "            sheet_no_na = filteredSheet.dropna(subset = [english_col, lang], inplace=False)\n",
    "            sheet_new = sheet_no_na.rename(columns = {english_col: 'Key'}, inplace=False)\n",
    "            count += sheet_new.count()\n",
    "            excelDf = pd.concat([excelDf, sheet_new], axis=0)\n",
    "            \n",
    "    excelDf = excelDf.apply(set_variables, axis=1)\n",
    "    return excelDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllTranslations():\n",
    "    \n",
    "\n",
    "    locales = languages\n",
    "    all_translations = pd.DataFrame()\n",
    "    langs_translations = []\n",
    "    for locale, language in locales:\n",
    "        global lang\n",
    "        lang = language\n",
    "        path_to_xl = './'+ locale\n",
    "        excel_files = sorted(os.listdir(path_to_xl))\n",
    "#         translation_excel_files = [pos_json for pos_json in excel_files if pos_json.endswith('.xlsx') and not pos_json.startswith('~')]\n",
    "        translation_excel_files = ['latest.xlsx']\n",
    "        \n",
    "        excelDf = getTranslationFromSheets(locale, translation_excel_files)\n",
    "        out_df = readInputJsonAsDf('./../../../crowdsource-ui/locales/{locale}.json'.format(locale=locale))\n",
    "    \n",
    "        filter_chars = [':','-']\n",
    "    \n",
    "        excelDf['Key_lower'] = excelDf['Key'].str.lower().str.strip()\n",
    "        excelDf[language] = excelDf[language].str.strip()\n",
    "        excelDf = excelDf.drop_duplicates(subset=['Key_lower'], keep='last')\n",
    "        excelDf.Key_lower=excelDf.Key_lower.apply(lambda x: re.sub(r' -$','',re.sub(r'^X ','',re.sub(r'^x ','',str(x)))))\n",
    "        excelDf[language]=excelDf[language].apply(lambda x: re.sub(r' -$','',re.sub(r'^X ','',re.sub(r'^x ','',str(x)))))\n",
    "\n",
    "        \n",
    "        out_df['Key_lower'] = out_df['Key'].str.lower().str.strip()\n",
    "        \n",
    "        \n",
    "        excelDf_dropped = excelDf.drop_duplicates(subset=['Key_lower'], keep='first')\n",
    "        out_df_dropped = out_df.drop_duplicates(subset=['Key'], keep='first')\n",
    "        \n",
    "        lang_translations = pd.DataFrame()\n",
    "        lang_translations = lang_translations.append(excelDf_dropped[['Key',language]])\n",
    "#         lang_translations = lang_translations.rename(columns = {\"Key\": language+'_key'}, inplace=False)\n",
    "#         lang_translations = lang_translations.rename(columns = {language: language+'_value'}, inplace=False)\n",
    "        \n",
    "        all_translations = all_translations.append(lang_translations)\n",
    "        \n",
    "        merged_df = pd.merge(excelDf_dropped, out_df_dropped, on=\"Key_lower\", how='right')\n",
    "        new_trans = pd.merge(excelDf_dropped, out_df_dropped, on=\"Key_lower\", how='inner')\n",
    "\n",
    "        merged_df = merged_df.apply(set_values, axis = 1)\n",
    "\n",
    "        select_columns = ['Key_y', 'value']\n",
    "\n",
    "        filtered_merged_df = merged_df[select_columns]\n",
    "\n",
    "        final_df = filtered_merged_df.drop_duplicates(subset='Key_y', keep='first', inplace=False)\n",
    "        print(new_trans.shape)\n",
    "\n",
    "        jsonFile = final_df.to_json(orient='values')\n",
    "        jsonFile = json.loads(jsonFile)\n",
    "        \n",
    "        final_final_json = reformat_json(jsonFile)\n",
    "        \n",
    "        output_json_file = locale + '.json'\n",
    "        langs_translations.append(lang_translations)\n",
    "\n",
    "        with open(output_json_file, 'w') as f:\n",
    "            f.write(json.dumps(final_final_json, indent = 4, ensure_ascii=False))\n",
    "#     save_xls(langs_translations,'./allTrans.xlsx')\n",
    "\n",
    "    return all_translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your selected language</td>\n",
       "      <td>आपकी चुनी हुई भाषा</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Top languages</td>\n",
       "      <td>मुख्य भाषाएं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suggestion</td>\n",
       "      <td>सुझाव</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Complaint</td>\n",
       "      <td>शिकायत</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Compliment</td>\n",
       "      <td>सराहना</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Key               Hindi\n",
       "1  Your selected language  आपकी चुनी हुई भाषा\n",
       "2           Top languages        मुख्य भाषाएं\n",
       "3              Suggestion               सुझाव\n",
       "4               Complaint              शिकायत\n",
       "5              Compliment              सराहना"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all = getAllTranslations()\n",
    "all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-14a4275b1c20>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-14a4275b1c20>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    all 219\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKeysWithoutTranslation(lang):\n",
    "    with open('./../../../crowdsource-ui/locales/{lang}.json'.format(lang=lang)) as f:\n",
    "        js = json.load(f)\n",
    "    \n",
    "    keys_list = []\n",
    "    total = 0\n",
    "    for key, value in js.items():\n",
    "        total+=1\n",
    "        if key == value:\n",
    "            keys_list.append(key)\n",
    "#     print(len(keys_list))\n",
    "    return total, keys_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi 35\n",
      "gu 205\n",
      "as 76\n",
      "bn 65\n",
      "ta 68\n",
      "te 62\n",
      "mr 90\n",
      "pa 82\n",
      "ml 65\n",
      "or 246\n",
      "kn 61\n",
      "en 637\n"
     ]
    }
   ],
   "source": [
    "languages = ['hi','gu','as','bn','ta','te','mr','pa','ml','or','kn','en']\n",
    "for lang_code in languages:\n",
    "    total, val = findKeysWithoutTranslation(lang_code)\n",
    "    print(lang_code, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "Speech Recognition Models\n",
      "Select the language you wish to contribute/validate in:\n",
      "Vakyansh has been envisioned to meet a goal of approx. 10,000 hours of diversified Indian voices.\n",
      "Terms of Use\n",
      "Copyright & Licensing Notice\n",
      "For the development of speech recognition models in Indian languages, there is a need for an open data repository of diversified Indian voices.Vakyansh invites you to reach out and contribute your voice to create a diverse open data repository of Indian voices.\n",
      "The key to building speech recognition models, lies in the diversity of the data that you provide by contributing across states, dialects, accents, gender and age group.The magnitude of this diversity across the nation, gives us collective strength in empowering our languages.\n",
      "Ensure the voice is <b>clear and audible</b>\n",
      "Match the voice to the text <b>accurately</b>\n",
      "You are just <span id=\"remainingSentences\"></span> sentences away from earning your <span id=\"badgeName\"></span> Badge.\n",
      "Low/No Ambient Noise\n",
      "\n",
      "Back to LikhoIndia Home\n",
      "Your language pair and top 3 most contributed language pairs\n",
      "Help us understand what’s wrong with the image labelled\n",
      "Select page\n",
      "Back to Bolo India Home\n",
      "Validate what they say\n",
      "Your feedback helps us keep Suno India relevant, we appreciate you taking time to leave the feedback.\n",
      "Your feedback helps us keep Likho India relevant, we appreciate you taking time to leave the feedback.\n",
      "Your feedback helps us keep Dekho India relevant, we appreciate you taking time to leave the feedback.\n",
      "Be a part of language initiative, earn badges and make a difference?\n",
      "Opt-out displayed data\n",
      "Duration validated\n",
      "Duration transcribed\n",
      "Validations\n",
      "Bolo India creates a repository of diverse voices speaking Indian languages, where volunteer reads the corresponding text.\n",
      "Suno India creates an open dataset through transcription of audio files.\n",
      "Enrich Indian languages become atma-nirbhar through these datasets.\n",
      "Enrich your own language\n",
      "Enrich us understand what’s wrong with the image labelled\n",
      "BhashaDaan: A crowdsourcing initiative for Indian languages\n",
      "<span id=\"current_badge_name_1\"></span> contributor level achieved for validating <span id=\"current_badge_count\"></span> labelling images.\n",
      "Become a Bhasha Samarthak by contributing to Bolo India, Suno India, Likho India or Dekho India. Earn Bronze/Silver/Gold/Platinum Bhasha Samarthak Badges based on your contributions. Share them in your social circle, your language community, and motivate your friends and family to contribute to the cause.\n",
      "Become a Bhasha Samarthak by contributing to these initiatives. For details on how to earn Bhasha Samarthak Badges, please select the initiative and language of your choice.\n",
      "Levels and badges may take upto 48 hours to update. Your contribution will be validated before confirming the badge. Please keep contributing actively to stand a chance to get recognised.\n",
      "Duration recorded\n",
      "Help to build an open repository of data to digitally enrich your language\n",
      "Contribute and become a Bhasha Samarthak\n",
      "Bronze Bhasha Samarthak Badge\n",
      "If you are the copyright holder of this data and believe it should not be used on the platform, please send us an email to <span class=\"email\">optout@bhashini.gov.in</span><span class=\"tooltiptext\" id=\"myDataSourceTooltip\">Copy to clipboard</span> with evidence that you are indeed the copyright holder of this data.\n",
      "You are enriching your language\n",
      "You are just <span id=\"sentense_away_count\"></span> recordings away from earning your <span id=\"next_badge_name\"></span>  Bhasha Samarthak Badge. <a href=\"badges.html\">Know more</a>\n",
      "<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge earned for contributing <span id=\"current_badge_count\"></span> sentences.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> ${text} to earn your Bhasha Samarthak <span id=\"next_badge_name_1\"></span> Badge. <a href=\"./badges.html\">Know more</a>\n",
      "You’ve earned your <span id=\"current_badge_name\"></span> Bhasha Samarthak Badge\n",
      "<span id=\"current_badge_name\"></span> Bhasha Samarthak Badge earned for contributing <span id=\"current_badge_count\"></span> recordings\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> recordings to earn your <span id=\"next_badge_name_1\"></span>  Bhasha Samarthak Badge. <a href=\"badges.html\">Know more</a>\n",
      "All fields are optional but you can enhance your contribution by providing non personal demographic details.\n",
      "You are just <span id=\"sentense_away_count\"></span> sentences away from earning your  <span id=\"next_badge_name\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to earn your Bhasha Samarthak <span id=\"next_badge_name_1\"></span> Badge. <a href=\"./badges.html\">Know more</a>\n",
      "You are just <span id=\"sentense_away_count\"></span> sentences away from earning your <span id=\"next_badge_name\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to unlock your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Thank you for your for translation efforts\n",
      "You are just <span id=\"sentense_away_count\"></span> sentences away from earning your <span id=\"next_badge_name\"></span> Bhasha Samarthak  Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to unlock your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak  Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Thank you for your effort to validate translations.\n",
      "You are just <span id=\"sentense_away_count\"></span> images labelled away from earning your <span id=\"next_badge_name\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "You are just <span id=\"sentense_away_count\"></span> images away from earning your Bhasha Samarthak <span id=\"next_badge_name\"></span> Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to unlock your <span id=\"next_badge_name_1\"></span>  Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> recordings to earn your Bhasha Samarthak <span id=\"next_badge_name_1\"></span> Badge. <a href=\"./badges.html\">Know more</a>\n",
      "<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge earned for contributing <span id=\"current_badge_count\"></span> recordings\n",
      "<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge earned for validating <span id=\"current_badge_count\"></span> recordings\n",
      "India\n",
      "(No Username)\n",
      "Only 12 characters allowed. (Hint: name.surname, name_surname12 etc.)\n",
      "Opt-out Notification\n",
      "<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge earned for contributing <span id=\"current_badge_count\"></span> recordings.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> recordings to earn your  <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge. <a href=\"./badges.html\">Know more</a>\n",
      "You earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by contributing <span id=\"current_badge_count\"></span> sentences.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge. <a href=\"./badges.html\">Know more</a>\n",
      "Thank you for correcting!\n",
      "You've earned a<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> recordings\n",
      "You are just <span id=\"sentense_away_count\"></span> images away from earning your <span id=\"next_badge_name\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "You earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by labelling <span id=\"current_badge_count\"></span> images.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> images to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge. <a href=\"./badges.html\">Know more</a>\n",
      "You’ve earned a<span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> recordings\n",
      "You’ve earned a  <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> sentences.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      " You’ve earned a  <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> sentences.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak  Badge. <a href=\"../badges.html\">Know more</a>\n",
      "You’ve earned a  <span id=\"current_badge_name_1\"></span>  Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> Images.\n",
      "Your next goal is to reach <span id=\"next_badge_count\"></span> sentences to earn your <span id=\"next_badge_name_1\"></span>  Bhasha Samarthak Badge. <a href=\"../badges.html\">Know more</a>\n",
      "recording(s) validated\n",
      "You’ve earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> recordings\n",
      "You've earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by contributing <span id=\"current_badge_count\"></span> sentences.\n",
      "You've earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by labelling <span id=\"current_badge_count\"></span> images.\n",
      "You've earned a  <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by contributing <span id=\"current_badge_count\"></span> recordings\n",
      "Contribute your voice by recording the sentence\n",
      "Validate the audios recorded by others\n",
      "Bhasha\n",
      "Daan\n",
      "Your contribution can empower Bhashini to make many such stories happen.\n",
      "Towards digital\n",
      "empowerment for all...\n",
      "Remove language barriers with\n",
      "*required\n",
      "optional\n",
      "Submitted successfully\n",
      "Thank you for your feedback!\n",
      "upto 10 (Kid)\n",
      "10 - 30 (Youth)\n",
      "30 - 60 (Adult)\n",
      "60+ (Senior)\n",
      "I've contributed towards building open language repository for India on https://bhashini.gov.in/bhashadaan You and I can make a difference by donating our voices that can help machines learn our language and interact with us through great linguistic applications. Do your bit and empower the language?\n",
      "Beta\n"
     ]
    }
   ],
   "source": [
    "keys_without_translation = pd.DataFrame()\n",
    "for lang_code, language in languages:\n",
    "    lang_list = findKeysWithoutTranslation(lang_code)\n",
    "    keys_without_translation[language+'_key'] = pd.Series(lang_list)\n",
    "\n",
    "keys_without_translation.head()\n",
    "# keys_without_translation[keys_without_translation['Tamil_key']=='image label(s)  contributed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "count = 0\n",
    "checkCount = 0\n",
    "for key, value in jsonFile:\n",
    "    x = re.search(\"^[\\u0020-\\u007F]+$\", value)\n",
    "    count += 1\n",
    "    if x:\n",
    "      checkCount += 1\n",
    "print(count, checkCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAndPrintResult(locale,lang, translation_excel_files):\n",
    "    for excel_file_name in translation_excel_files:\n",
    "        print(\"---------------\",excel_file_name, \"------------------\")\n",
    "        excel = pd.ExcelFile(locale + '/' + excel_file_name)\n",
    "        for sheetName in excel.sheet_names:\n",
    "            sheet = excel.parse(sheet_name = sheetName, header=1)\n",
    "            FORMAT = ['English copy',lang]\n",
    "            for value in allowed_values:\n",
    "                if value in sheet.columns:\n",
    "                    FORMAT.append(value)\n",
    "            if 'English copy' not in sheet.columns:\n",
    "                print('{} does not have English copy or C in copy is in caps'.format(sheetName))\n",
    "            if lang not in sheet.columns:\n",
    "                print('{} does not have {} column or has some hidden sheet(If so, unhide and delete it).'.format(sheetName, lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale = 'kn'\n",
    "path_to_xl= './'+ locale\n",
    "excel_files = sorted(os.listdir(path_to_xl))\n",
    "translation_excel_files = [pos_json for pos_json in excel_files if pos_json.endswith('.xlsx') and not pos_json.startswith('~')]\n",
    "validateAndPrintResult(locale,'Kannada', translation_excel_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
