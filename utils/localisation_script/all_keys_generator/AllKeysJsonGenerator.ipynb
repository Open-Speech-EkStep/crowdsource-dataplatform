{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1ee701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d132d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(json_data):\n",
    "    out_df = pd.DataFrame(list(json_data.items()),\n",
    "                       columns=[key_column, english_col])        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b4d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file_path):\n",
    "    with open(json_file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc08179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(json_obj):\n",
    "    json_dict = {}\n",
    "    for key, value in json_obj:\n",
    "        json_dict[key] = value\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e09001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(df_row):\n",
    "    for value in allowed_values:\n",
    "        try:\n",
    "            if pd.notna(df_row[value]):\n",
    "                df_row[english_col] = df_row[english_col].replace('<'+ value + '>', df_row[value])\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        if pd.notna(df_row['a-tag-replacement']):\n",
    "            start_index = df_row[english_col].find('<a')+2\n",
    "            end_index = df_row[english_col].find('>')\n",
    "            df_row[english_col] = df_row[english_col][:start_index] + df_row['a-tag-replacement'] + df_row[english_col][end_index:]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af337593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_json(df, output_json_path):\n",
    "    jsonFile = df.to_json(orient='values')\n",
    "    json_string = json.loads(jsonFile)\n",
    "\n",
    "    reformatted_json = reformat_json(json_string)\n",
    "\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        f.write(json.dumps(reformatted_json, indent = 4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd62ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_count(excel_df, merged_df):\n",
    "    count = 0\n",
    "    for key in excel_df[key_column]:\n",
    "        for k_key in merged_df[key_column]:\n",
    "            if key == k_key:\n",
    "                count+=1\n",
    "                break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be16c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df_no_na = df.dropna(subset = [key_column], inplace=False)\n",
    "    df_fill_na = df.fillna(value=\"\")\n",
    "    df_no_duplicates = df_fill_na.drop_duplicates(subset=[key_column], keep='last')\n",
    "    return df_no_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b9dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_as_df(excel_file):\n",
    "    excel = pd.ExcelFile(excel_file)\n",
    "    if len(excel.sheet_names) == 0:\n",
    "        return None\n",
    "    sheet = excel.parse(sheet_name = excel.sheet_names[0], header=1)\n",
    "    return sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62dedcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excels_as_df(file):\n",
    "    excel = pd.ExcelFile(file)\n",
    "    sheets_df_list = []\n",
    "    for sheet_name in excel.sheet_names:\n",
    "        sheet = excel.parse(sheet_name = sheet_name, header=1)\n",
    "        if(len(sheet.columns) == 0):\n",
    "            continue\n",
    "        sheet = sheet.dropna(how='all')\n",
    "        sheet = sheet.dropna(axis=1, how='all')\n",
    "        sheets_df_list.append(sheet)\n",
    "    return sheets_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c76a5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manually_generated_excel_file(excel_file):\n",
    "    sheet_df_list = read_excels_as_df(excel_file)\n",
    "    main_columns = ['Suno India', 'Likho India', 'Bolo India', 'Dekho India', 'English Content']\n",
    "\n",
    "    final_df = pd.DataFrame([], columns=[key_column, english_col])\n",
    "\n",
    "    for sheet_df in sheet_df_list:\n",
    "        columns = [column_name.rstrip().lstrip() for column_name in list(sheet_df.columns)]\n",
    "        for main_column in main_columns:\n",
    "            if main_column in columns:\n",
    "                try:\n",
    "                    filtered_sheet = sheet_df[[main_column+\" Key\", main_column]]\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                renamed_df = filtered_sheet.rename(columns={main_column+\" Key\": key_column, main_column: english_col})\n",
    "                renamed_df = renamed_df.dropna(subset=[key_column])\n",
    "                final_df = pd.concat([final_df, renamed_df],ignore_index = True)\n",
    "    return final_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d35207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_old_translations(modified_content_keys, languages, base_path, output_path):\n",
    "    \n",
    "    for language_code in languages.keys():\n",
    "        input_json_path = os.path.join(base_path,'{language_code}.json'.format(language_code=language_code))\n",
    "        language_data = read_json(input_json_path)\n",
    "        for key in modified_content_keys:\n",
    "            language_data[key] = key\n",
    "        output_json_path = os.path.join(output_path,'{language_code}.json'.format(language_code=language_code))\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            f.write(json.dumps(language_data, indent = 4, ensure_ascii=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c39d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_content(excel_df, json_df):\n",
    "    jsonFile = json_df.to_json(orient='values')\n",
    "    json_string = json.loads(jsonFile)\n",
    "\n",
    "    reformatted_json = reformat_json(json_string)\n",
    "    \n",
    "    changed_content = {}\n",
    "    for i,row in excel_df.iterrows():\n",
    "        key = row[key_column]\n",
    "        if key in reformatted_json and (row[english_col] != reformatted_json[key]):\n",
    "            changed_content[key] = {'old': reformatted_json[key],'new': row[english_col]}\n",
    "    return changed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "822bd08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_removed_keys(excel_df, json_df):\n",
    "    s = set(json_df[key_column])\n",
    "    f = set(excel_df[key_column])\n",
    "\n",
    "    difference = list(s - f)\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91973bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_report(report_json, report_type):\n",
    "    now = datetime.now()\n",
    "    report_json['last_run_timestamp'] = str(now)\n",
    "    os.makedirs('reports',exist_ok=True)\n",
    "    with open('{}/report_{}_{}.json'.format('reports', report_type, now), 'w') as f:\n",
    "        f.write(json.dumps(report_json, indent = 4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63cad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(json_df, excel_df, modified_content_keys):\n",
    "    report = {}\n",
    "    removed_keys = get_removed_keys(excel_df, json_df)\n",
    "    report['total_keys_in_json'] = int(json_df[key_column].count())\n",
    "    report['total_keys_received_in_excel'] = int(excel_df[key_column].count())\n",
    "    report['total_content_updated'] = len(modified_content_keys)\n",
    "    report['total_content_removed'] = len(removed_keys)\n",
    "    report['removed_keys'] = removed_keys\n",
    "    report['updated_content'] = modified_content_keys\n",
    "    export_report(report, 'json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "799c93b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_column = 'Key'\n",
    "english_col = 'English copy'\n",
    "allowed_values = ['x','y','z','u','v','w']    \n",
    "languages = {'hi': \"Hindi\",'gu': \"Gujarati\",'as': \"Assamese\",'bn':'Bengali','ta':\"Tamil\",\n",
    "             'te':\"Telugu\",'mr':\"Marathi\",'pa':\"Punjabi\",'ml':\"Malayalam\",'or':\"Odia\",'kn':\"Kannada\"}\n",
    "\n",
    "\n",
    "def generate(input_excel_path,input_json_path, output_json_path, input_category):    \n",
    "    if input_category == 'auto-generated':\n",
    "        excel_df = read_excel_as_df(input_excel_path)\n",
    "        excel_df = excel_df.apply(set_variables, axis = 1)\n",
    "    else:\n",
    "        excel_df = read_manually_generated_excel_file(input_excel_path)\n",
    "    existing_locale_json_data = read_json(input_json_path)\n",
    "    json_df = load_json_as_df(existing_locale_json_data)\n",
    "\n",
    "    clean_excel_df = clean_df(excel_df)\n",
    "    clean_json_df = clean_df(json_df)\n",
    "    \n",
    "    merged_df = pd.merge(clean_excel_df, clean_json_df[[key_column]], on=key_column, how='left')\n",
    "    \n",
    "    filtered_df = merged_df[[key_column, english_col]]\n",
    "\n",
    "    final_df = filtered_df.drop_duplicates(subset=[key_column], keep='first', inplace=False)\n",
    "\n",
    "    write_df_to_json(final_df, os.path.join(output_json_path,'en.json'))\n",
    "    \n",
    "    return clean_excel_df, clean_json_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a12758",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '''\n",
    "        Example commands:\n",
    "        \n",
    "        To run with auto-generated excel from AllKeysExcelGenerator.py:\n",
    "            python AllKeysJsonGenerator.py -i ./../../../crowdsource-ui/locales -e ./en/out/en.xlsx -o ./out/\n",
    "        \n",
    "        To run with manually generated excel with the 4 categories('Suno India', 'Bolo India', 'Likho India', 'Dekho India'):\n",
    "            python AllKeysJsonGenerator.py -i ./../../../crowdsource-ui/locales -e ./../test-data/read-data-from-table/English_content.xlsx  -o ./out/ -c manual\n",
    "    \n",
    "    '''\n",
    "\n",
    "parser = argparse.ArgumentParser(epilog=example,\n",
    "                                 formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "parser.add_argument(\"-c\", \"--input-category\", default= 'auto-generated',help = \"Format of the input used\", choices=['auto-generated','manual'])\n",
    "parser.add_argument(\"-i\", \"--input-base-path\", required=True, help = \"Path of folder with all jsons present\")\n",
    "parser.add_argument(\"-e\", \"--input-excel-path\", required=True, help = \"Path of excel file\")\n",
    "parser.add_argument(\"-o\",\"--output-json-path\", required=True, help = \"Output path\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"-i ./../../../crowdsource-ui/locales/ -e ./../test-data/read-data-from-table/English_content.xlsx -o ./out/ -c manual\".split())\n",
    "\n",
    "input_excel_path = args.input_excel_path\n",
    "input_base_path = args.input_base_path\n",
    "input_json_path = os.path.join(input_base_path, 'en.json')\n",
    "output_json_path = args.output_json_path\n",
    "input_category = args.input_category\n",
    "\n",
    "os.makedirs(output_json_path, exist_ok=True)\n",
    "\n",
    "excel_df, json_df = generate(input_excel_path, input_json_path, output_json_path, input_category)\n",
    "\n",
    "modified_content = get_modified_content(excel_df, json_df)\n",
    "clean_old_translations(list(modified_content.keys()), languages, input_base_path, output_json_path)\n",
    "os.system('python ./../clean_unused_keys/CleanLocaleJsons.py -i ./out -o ./out -a')\n",
    "generate_report(json_df, excel_df, modified_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
