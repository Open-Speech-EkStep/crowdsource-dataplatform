{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a375d3",
   "metadata": {},
   "source": [
    "# Generate local files with the received delta translated excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a0dbe",
   "metadata": {},
   "source": [
    "Read file in added data order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74efc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d52452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(json_data):\n",
    "    out_df = pd.DataFrame(list(json_data.items()),\n",
    "                       columns=['Key', 'value'])        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210a3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file_path):\n",
    "    with open(json_file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9f3aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(json_obj):\n",
    "    json_dict = {}\n",
    "    for key, value in json_obj:\n",
    "        json_dict[key] = value\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1804117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(df_row):\n",
    "    if pd.notnull(df_row[lang]):\n",
    "        df_row['value'] = df_row[lang]\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8a34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(df_row):\n",
    "    for value in allowed_values:\n",
    "        try:\n",
    "            if pd.notna(df_row[value]):\n",
    "                df_row[lang] = df_row[lang].replace('<'+ value + '>', df_row[value])\n",
    "                df_row['English value'] = df_row['English value'].replace('<'+ value + '>', df_row[value])\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        if pd.notna(df_row['a-tag-replacement']):\n",
    "            start_index = df_row[lang].find('<a')+2\n",
    "            end_index = df_row[lang].find('>')\n",
    "            df_row[lang] = df_row[lang][:start_index] + df_row['a-tag-replacement'] + df_row[lang][end_index:]\n",
    "            df_row['English value'] = df_row['English value'][:start_index] + df_row['a-tag-replacement'] + df_row['English value'][end_index:]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da945260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_json(df, output_json_path):\n",
    "    jsonFile = df.to_json(orient='values')\n",
    "    json_string = json.loads(jsonFile)\n",
    "\n",
    "    reformatted_json = reformat_json(json_string)\n",
    "\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        f.write(json.dumps(reformatted_json, indent = 4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0858b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_count(excel_df, merged_df):\n",
    "    count = 0\n",
    "    for key in excel_df['Key']:\n",
    "        for k_key in merged_df['Key']:\n",
    "            if key == k_key:\n",
    "                count+=1\n",
    "                break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba49d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_as_df(file, language_name):\n",
    "    excel = pd.ExcelFile(file)\n",
    "    for sheet_name in excel.sheet_names:\n",
    "        sheet = excel.parse(sheet_name = sheet_name, header=0)\n",
    "        if(len(sheet.columns) == 0):\n",
    "            continue\n",
    "        return sheet\n",
    "    return pd.DataFrame([], columns=[english_col, language_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a9d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_df(df):\n",
    "    out_df = df.copy()\n",
    "    out_df_dropped = out_df.drop_duplicates(subset=['Key'], keep='first')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fe7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_read_excel_df(df, language_name):\n",
    "    FORMAT = [english_col,language_name]\n",
    "    for value in allowed_values:\n",
    "        if value in df.columns:\n",
    "            FORMAT.append(value)\n",
    "    filtered_sheet = df[FORMAT]\n",
    "    sheet_no_na = filtered_sheet.dropna(subset = [english_col, language_name], inplace=False)\n",
    "    sheet_new = sheet_no_na.rename(columns = {english_col: 'English value'}, inplace=False)\n",
    "    return sheet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06cb3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel_df(df, language_name):\n",
    "    excel_df = df.copy()\n",
    "    try:\n",
    "        excel_df[language_name] = excel_df[language_name].str.strip()\n",
    "    except:\n",
    "        pass\n",
    "    excel_df = excel_df.drop_duplicates(subset=['English value'], keep='last')\n",
    "    excel_df[language_name]=excel_df[language_name].apply(lambda x: re.sub(r' -$','',re.sub(r'^X ','',re.sub(r'^x ','',str(x)))))\n",
    "    return excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71f3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excels_as_df(translation_excel_files, language_code, language_name):\n",
    "    excel_df = pd.DataFrame([], columns=[english_col, language_name])\n",
    "    for excel_file_name in translation_excel_files:\n",
    "        excel = pd.ExcelFile(excel_file_name)\n",
    "        for sheet_name in excel.sheet_names:\n",
    "            sheet = excel.parse(sheet_name = sheet_name, header=0)\n",
    "            if(len(sheet.columns) == 0):\n",
    "                continue\n",
    "            excel_df = pd.concat([excel_df, sheet], axis=0)\n",
    "    return excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b05b0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_excel_files(dir_name):\n",
    "    list_of_files = filter(os.path.isfile, glob.glob(dir_name + '/*'))\n",
    "    list_of_files = sorted(list_of_files, key = os.path.getmtime)\n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04414a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excels(input_base_path, language_code, language_name, meta_excel_df):\n",
    "    path_to_excels = '{}/{}'.format(input_base_path,language_code)\n",
    "#     excel_files = sorted(os.listdir(path_to_excel))\n",
    "    \n",
    "    translation_excel_files = get_excel_files(path_to_excels)\n",
    "#     translation_excel_files = [path_to_excel+\"/\"+ excel_file_name for excel_file_name in excel_files if excel_file_name.endswith('.xlsx') and not excel_file_name.startswith('~')]\n",
    "    \n",
    "    \n",
    "    excel_df = read_excels_as_df(translation_excel_files, language_code, language_name)\n",
    "    excel_df = clean_read_excel_df(excel_df, language_name)\n",
    "    \n",
    "    merged_excel_df = pd.merge(excel_df, meta_excel_df, left_on=\"English value\", right_on=\"English copy\", how='outer')\n",
    "    del merged_excel_df[\"English copy\"]\n",
    "\n",
    "    merged_excel_df = merged_excel_df.apply(set_variables, axis=1)\n",
    "\n",
    "    return merged_excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af846a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locale_data(input_base_path,input_json_path, language_code, language_name, meta_excel_df):\n",
    "    global lang\n",
    "    lang = language_name\n",
    "    \n",
    "    excel_df = read_excels(input_base_path, language_code, language_name, meta_excel_df)\n",
    "    existing_locale_json_data = read_json('{input_json_path}/{locale}.json'.format(input_json_path=input_json_path,locale=language_code))\n",
    "    out_df = load_json_as_df(existing_locale_json_data)\n",
    "\n",
    "    excelDf_dropped = clean_excel_df(excel_df, language_name)\n",
    "    out_df_dropped = clean_json_df(out_df)\n",
    "    \n",
    "    merged_df = pd.merge(excelDf_dropped, out_df_dropped, left_on=\"Key\", right_on=\"Key\", how='right')\n",
    "\n",
    "    merged_df = merged_df.apply(set_values, axis = 1)\n",
    "    \n",
    "    select_columns = ['Key', 'value']\n",
    "\n",
    "    filtered_merged_df = merged_df[select_columns]\n",
    "\n",
    "    final_df = filtered_merged_df.drop_duplicates(subset='Key', keep='first', inplace=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    return excelDf_dropped, final_df, merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed556f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_col = 'English copy'\n",
    "allowed_values = ['x','y','z','u','v','w']\n",
    "\n",
    "def gen_locales(languages, input_base_path, input_json_path, meta_input_path, output_base_path):\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "    for language_code, language_name in languages:\n",
    "        meta_excel_path = meta_input_path+\"/\"+language_code+\".xlsx\"\n",
    "        meta_excel_df = read_excel_as_df(meta_excel_path,  language_name)\n",
    "        del meta_excel_df[language_name]\n",
    "\n",
    "        excelDf_dropped, final_df, merged_df = get_locale_data(input_base_path,input_json_path, language_code, language_name, meta_excel_df)\n",
    "\n",
    "        print(\"****** LOCALE = {} **********\".format(language_name))\n",
    "        print(\"Final Number of Keys(WithoutDuplicates/WithDuplicates) = {}/{}\".format(final_df['Key'].nunique(), final_df['Key'].count()))\n",
    "        print(\"Matched Keys => {}/{}\".format(get_matched_count(excelDf_dropped, merged_df), excelDf_dropped['Key'].count()))\n",
    "        print(\"****************\")\n",
    "        output_json_path = '{base_path}/{language}.json'.format(base_path=output_base_path, language=language_code)\n",
    "        write_df_to_json(final_df, output_json_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6949685",
   "metadata": {},
   "source": [
    "## MAIN CELL TO RUN LOCALE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de274073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** LOCALE = Assamese **********\n",
      "Final Number of Keys(WithoutDuplicates/WithDuplicates) = 337/337\n",
      "Matched Keys => 5/5\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "languages = [('hi', \"Hindi\"),('gu', \"Gujarati\"),('as', \"Assamese\"),('bn','Bengali'),('ta',\"Tamil\"),\n",
    "             ('te',\"Telugu\"),('mr',\"Marathi\"),('pa',\"Punjabi\"),('ml',\"Malayalam\"),('or',\"Odia\"),('kn',\"Kannada\")]\n",
    "input_base_path = \"./input_excel_files\"\n",
    "input_json_path = './../../../crowdsource-ui/locales'\n",
    "meta_input_path = \"./../delta_generation/out-meta\"\n",
    "output_base_path = \"./output_json_files\"\n",
    "\n",
    "gen_locales(languages, input_base_path,input_json_path, meta_input_path, output_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efedebd7",
   "metadata": {},
   "source": [
    "## Test cases for locale generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66b2d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** LOCALE = Hindi **********\n",
      "Final Number of Keys(WithoutDuplicates/WithDuplicates) = 16/16\n",
      "Matched Keys => 15/15\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "languages = [('hi','Hindi')]\n",
    "\n",
    "base_path = \"./../test-data/proper-locale-gen-check\"\n",
    "\n",
    "input_base_path = base_path+'/inputs'\n",
    "input_json_path = base_path\n",
    "meta_input_path = base_path+\"/out-meta\"\n",
    "output_base_path = base_path+\"/out_json\"\n",
    "\n",
    "gen_locales(languages, input_base_path,input_json_path, meta_input_path, output_base_path)\n",
    "\n",
    "\n",
    "hi_json = read_json(output_base_path+'/hi.json')\n",
    "\n",
    "assert len(hi_json) == 16\n",
    "assert hi_json['(No Username)'] == 'No'\n",
    "assert hi_json['10 - 30 (Youth)'] == '10 - 30 वर्ष (युवा)'\n",
    "assert hi_json['<a class=\"\" href=\"/\">Click Here</a> to go back to home page'] == 'अपने होम पेज पर जाने के लिए <a class=\"\" href=\"/\">यहाँ क्लिक</a> करें'\n",
    "assert hi_json['By proceeding ahead you agree to the <a href=\"../terms-and-conditions.html\" target=\"_blank\"> Terms and Conditions</a>'] == 'आगे बढ़ने का मतलब है कि आप इन <a href=\"../terms-and-conditions.html\" target=\"_blank\"> नियमों और शर्तों</a> से सहमत हैं'\n",
    "assert hi_json['By proceeding ahead you agree to the <a href=\"./terms-and-conditions.html\" target=\"_blank\"> Terms and Conditions</a>'] == 'आगे बढ़ने का मतलब है कि आप इन <a href=\"./terms-and-conditions.html\" target=\"_blank\"> नियमों और शर्तों</a> से सहमत हैं'\n",
    "assert hi_json['Contributions'] == 'योगदान'\n",
    "assert hi_json['Female'] == 'महिला'\n",
    "assert hi_json['Language'] == 'हिंदी'\n",
    "assert hi_json['Get started by clicking on <b>Record</b> button'] == \"'रिकॉर्ड करें' बटन पर क्लिक करके शुरू करें\"\n",
    "assert hi_json['TO'] == 'इस भाषा में'\n",
    "assert hi_json['Validate More'] == 'और सत्यापन करें'\n",
    "assert hi_json['You’ve earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> Images.'] == 'आपने <span id=\"current_badge_count\"></span> इमेज को सत्यापित करके एक <span id=\"current_badge_name_1\"></span> भाषा समर्थक बैज जीता है।'\n",
    "assert hi_json['image label(s) validated'] == 'इमेज लेबल सत्यापित किए गए'\n",
    "assert hi_json['Your next goal is to reach <span id=\"next_badge_count\"></span> images to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge.'] == 'अपना <span id=\"next_badge_name_1\"></span> भाषा समर्थक बैज जीतने के लिए आपका अगला लक्ष्य <span id=\"next_badge_count\"></span> इमेज तक पहुंचना है।'\n",
    "\n",
    "assert hi_json['social sharing text with rank'] == 'मैंने https://bhashini.gov.in/bhashadaan पर भारत के लिए ओपन लैंग्वेज रिपॉज़िटरी बनाने में योगदान किया है। आप और मैं हमारी आवाज़ों का योगदान करके इस पहल में काफ़ी फ़र्क डाल सकते हैं जिससे मशीन को हमारी भाषा सीखने में मदद मिलती है। \\\\\"बोलो इंडिया\\\\\" पर हमारी <x> भाषा का रैंक <y> है। अपनी भाषा को सशक्त बनाने में अपना योगदान देना चाहेंगे?'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
