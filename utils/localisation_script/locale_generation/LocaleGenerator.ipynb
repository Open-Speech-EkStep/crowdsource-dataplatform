{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479e685f",
   "metadata": {},
   "source": [
    "# Generate local files with the received delta translated excel files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6817a1",
   "metadata": {},
   "source": [
    "Read file in added data order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fbbdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b817cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(json_data):\n",
    "    out_df = pd.DataFrame(list(json_data.items()),\n",
    "                       columns=['Key', 'value'])        \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b090f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file_path):\n",
    "    with open(json_file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816e2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_json(json_obj):\n",
    "    json_dict = {}\n",
    "    for key, value in json_obj:\n",
    "        json_dict[key] = value\n",
    "    return json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d08b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(df_row):\n",
    "    try:\n",
    "        if pd.notnull(df_row[lang]) and len(str(df_row[lang]).strip()) != 0:\n",
    "            df_row['value'] = df_row[lang]\n",
    "    except:\n",
    "        print(df_row[lang])\n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b40dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(df_row):\n",
    "    for value in allowed_values:\n",
    "        try:\n",
    "            if pd.notna(df_row[value]):\n",
    "                df_row[lang] = df_row[lang].replace('<'+ value + '>', df_row[value])\n",
    "                df_row['English value'] = df_row['English value'].replace('<'+ value + '>', df_row[value])\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        if pd.notna(df_row['a-tag-replacement']):\n",
    "            start_index = df_row[lang].find('<a')+2\n",
    "            end_index = df_row[lang].find('>')\n",
    "            df_row[lang] = df_row[lang][:start_index] + df_row['a-tag-replacement'] + df_row[lang][end_index:]\n",
    "            df_row['English value'] = df_row['English value'][:start_index] + df_row['a-tag-replacement'] + df_row['English value'][end_index:]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return df_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41588ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_df_to_json(df, output_json_path):\n",
    "    jsonFile = df.to_json(orient='values')\n",
    "    json_string = json.loads(jsonFile)\n",
    "\n",
    "    reformatted_json = reformat_json(json_string)\n",
    "\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        f.write(json.dumps(reformatted_json, indent = 4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4b58c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_count(excel_df, merged_df):\n",
    "    count = 0\n",
    "    for key in excel_df['Key']:\n",
    "        for k_key in merged_df['Key']:\n",
    "            if key == k_key:\n",
    "                count+=1\n",
    "                break\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87167833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_as_df(file, language_name):\n",
    "    excel = pd.ExcelFile(file)\n",
    "    for sheet_name in excel.sheet_names:\n",
    "        sheet = excel.parse(sheet_name = sheet_name, header=0)\n",
    "        if(len(sheet.columns) == 0):\n",
    "            continue\n",
    "        return sheet\n",
    "    return pd.DataFrame([], columns=[english_col, language_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcba90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json_df(df):\n",
    "    out_df = df.copy()\n",
    "    out_df_dropped = out_df.drop_duplicates(subset=['Key'], keep='first')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f24a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_read_excel_df(df, language_name):\n",
    "    FORMAT = [english_col,language_name]\n",
    "    for value in allowed_values:\n",
    "        if value in df.columns:\n",
    "            FORMAT.append(value)\n",
    "    filtered_sheet = df[FORMAT]\n",
    "    sheet_no_na = filtered_sheet.dropna(subset = [english_col], inplace=False)\n",
    "    sheet_new = sheet_no_na.rename(columns = {english_col: 'English value'}, inplace=False)\n",
    "    return sheet_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "931314e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel_df(df, language_name):\n",
    "    excel_df = df.copy()\n",
    "    try:\n",
    "        for i, row in excel_df.iterrows():\n",
    "            if pd.notna(row[language_name]):\n",
    "                row[language_name] = str(row[language_name]).strip()\n",
    "    except:\n",
    "        pass\n",
    "    excel_df = excel_df.drop_duplicates(subset=['English value'], keep='last')\n",
    "    return excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde99e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excels_as_df(translation_excel_files, language_code, language_name):\n",
    "    excel_df = pd.DataFrame([], columns=[english_col, language_name])\n",
    "    for excel_file_name in translation_excel_files:\n",
    "        excel = pd.ExcelFile(excel_file_name)\n",
    "        for sheet_name in excel.sheet_names:\n",
    "            sheet = excel.parse(sheet_name = sheet_name, header=0)\n",
    "            if(len(sheet.columns) == 0):\n",
    "                continue\n",
    "            excel_df = pd.concat([excel_df, sheet], axis=0)\n",
    "    return excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aa1a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_filter(excel_file_name):\n",
    "    return os.path.isfile(excel_file_name) and excel_file_name.endswith('.xlsx') and not excel_file_name.split('/')[-1].startswith('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6d50abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_excel_files(path_to_excels, translation_excel_files):\n",
    "    done_folder = path_to_excels+\"/done\"\n",
    "    os.makedirs(done_folder, exist_ok=True)\n",
    "    for excel_file in translation_excel_files:\n",
    "        os.system('mv {} {}'.format(excel_file, done_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e77e04bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_excel_files(dir_name):\n",
    "    list_of_files = filter(excel_filter, glob.glob(dir_name + '/*'))\n",
    "    list_of_files = sorted(list_of_files, key = os.path.getmtime)\n",
    "    return list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef3f8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excels(input_base_path, language_code, language_name, meta_excel_df):\n",
    "    path_to_excels = '{}/{}'.format(input_base_path,language_code)\n",
    "#     excel_files = sorted(os.listdir(path_to_excel))\n",
    "    \n",
    "    translation_excel_files = get_excel_files(path_to_excels)\n",
    "#     translation_excel_files = [path_to_excel+\"/\"+ excel_file_name for excel_file_name in excel_files if excel_file_name.endswith('.xlsx') and not excel_file_name.startswith('~')]\n",
    "    excel_df = read_excels_as_df(translation_excel_files, language_code, language_name)\n",
    "    move_excel_files(path_to_excels, translation_excel_files)\n",
    "    \n",
    "    excel_df = clean_read_excel_df(excel_df, language_name)\n",
    "    \n",
    "    merged_excel_df = pd.merge(excel_df, meta_excel_df, left_on=\"English value\", right_on=\"English copy\", how='outer')\n",
    "    del merged_excel_df[english_col]\n",
    "\n",
    "    merged_excel_df = merged_excel_df.apply(set_variables, axis=1)\n",
    "\n",
    "    return merged_excel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2813fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locale_data(input_base_path,input_json_path, language_code, language_name, meta_excel_df):\n",
    "    global lang\n",
    "    lang = language_name\n",
    "    \n",
    "    excel_df = read_excels(input_base_path, language_code, language_name, meta_excel_df)\n",
    "    existing_locale_json_data = read_json('{input_json_path}/{locale}.json'.format(input_json_path=input_json_path,locale=language_code))\n",
    "    out_df = load_json_as_df(existing_locale_json_data)\n",
    "\n",
    "    excelDf_dropped = clean_excel_df(excel_df, language_name)\n",
    "    out_df_dropped = clean_json_df(out_df)\n",
    "\n",
    "    merged_df = pd.merge(excelDf_dropped, out_df_dropped, left_on=\"Key\", right_on=\"Key\", how='right')\n",
    "    \n",
    "    merged_df = merged_df.apply(set_values, axis = 1)\n",
    "    \n",
    "    select_columns = ['Key', 'value']\n",
    "\n",
    "    filtered_merged_df = merged_df[select_columns]\n",
    "    \n",
    "    final_df = filtered_merged_df.drop_duplicates(subset='Key', keep='first', inplace=False)\n",
    "    return excelDf_dropped, final_df, merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "599df3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_col = 'English copy'\n",
    "allowed_values = ['x','y','z','u','v','w']\n",
    "\n",
    "def gen_locales(languages, input_base_path, input_json_path, meta_input_path, output_base_path):\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "    for language_code, language_name in languages:\n",
    "        meta_excel_path = meta_input_path+\"/\"+language_code+\".xlsx\"\n",
    "        meta_excel_df = read_excel_as_df(meta_excel_path,  language_name)\n",
    "        del meta_excel_df[language_name]\n",
    "\n",
    "        excelDf_dropped, final_df, merged_df = get_locale_data(input_base_path,input_json_path, language_code, language_name, meta_excel_df)\n",
    "\n",
    "        output_json_path = '{base_path}/{language}.json'.format(base_path=output_base_path, language=language_code)\n",
    "        write_df_to_json(final_df, output_json_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e86518",
   "metadata": {},
   "source": [
    "## MAIN CELL TO RUN LOCALE GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23bad655",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {'hi': \"Hindi\",'gu': \"Gujarati\",'as': \"Assamese\",'bn':'Bengali','ta':\"Tamil\",\n",
    "             'te':\"Telugu\",'mr':\"Marathi\",'pa':\"Punjabi\",'ml':\"Malayalam\",'or':\"Odia\",'kn':\"Kannada\"}\n",
    "\n",
    "example = '''\n",
    "        Example commands:\n",
    "        \n",
    "        For specific languages:\n",
    "            python LocaleGenerator.py -j ./../all_keys_generator/out -e ./input_excel_files -m ./../delta_generation/out-meta -o ./output_json_files -l gu pa\n",
    "        \n",
    "        For all languages:\n",
    "            python LocaleGenerator.py -j ./../all_keys_generator/out -e ./input_excel_files -m ./../delta_generation/out-meta -o ./output_json_files -a\n",
    "    '''\n",
    "\n",
    "parser = argparse.ArgumentParser(epilog=example,\n",
    "                                 formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "group = parser.add_mutually_exclusive_group(required=True)\n",
    "group.add_argument(\"-a\", \"--all-languages\", action=\"store_true\", help = \"Generate delta for all languages\")\n",
    "group.add_argument(\"-l\", \"--languages\", nargs=\"+\", help = \"Generate delta for the languages mentioned by language codes(space separated)\", choices=list(LANGUAGES.keys()))\n",
    "\n",
    "parser.add_argument(\"-e\", \"--excel-folder-path\", required=True, help = \"Input folder path with excel files present\")\n",
    "parser.add_argument(\"-j\", \"--json-folder-path\", required=True, help = \"Input folder path with json files present\")\n",
    "parser.add_argument(\"-m\", \"--meta-folder-path\", required=True, help = \"Input folder path with meta files for the excels present\")\n",
    "\n",
    "parser.add_argument(\"-o\", \"--output-folder-path\", required=True, help = \"Output folder path where excels are generated\")\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"-j ./../all_keys_generator/out -e ./input_excel_files -m ./../delta_generation/out-meta -o ./output_json_files -l as\".split())\n",
    "\n",
    "languages = {}\n",
    "if args.all_languages:\n",
    "    languages = LANGUAGES.copy()\n",
    "else:\n",
    "    language_codes = args.languages\n",
    "    for code in language_codes:\n",
    "        languages[code] = LANGUAGES[code]\n",
    "\n",
    "input_base_path = args.excel_folder_path\n",
    "input_json_path = args.json_folder_path\n",
    "meta_input_path = args.meta_folder_path\n",
    "output_base_path = args.output_folder_path\n",
    "\n",
    "gen_locales(languages.items(), input_base_path,input_json_path, meta_input_path, output_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9ae27",
   "metadata": {},
   "source": [
    "## Test cases for locale generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce10b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [('hi','Hindi')]\n",
    "\n",
    "base_path = \"./../test-data/proper-locale-gen-check\"\n",
    "\n",
    "input_base_path = base_path+'/inputs'\n",
    "input_json_path = base_path\n",
    "meta_input_path = base_path+\"/out-meta\"\n",
    "output_base_path = base_path+\"/out_json\"\n",
    "\n",
    "os.system('mv {} {}'.format(input_base_path+\"/hi/done/hi.xlsx\", input_base_path+\"/hi/\"))\n",
    "\n",
    "gen_locales(languages, input_base_path,input_json_path, meta_input_path, output_base_path)\n",
    "\n",
    "os.system('mv {} {}'.format(input_base_path+\"/hi/done/hi.xlsx\", input_base_path+\"/hi/\"))\n",
    "os.system('rm -rf {}'.format(input_base_path+\"/hi/done/\"))\n",
    "\n",
    "hi_json = read_json(output_base_path+'/hi.json')\n",
    "\n",
    "assert len(hi_json) == 16\n",
    "assert hi_json['(No Username)'] == 'No'\n",
    "assert hi_json['10 - 30 (Youth)'] == '10 - 30 वर्ष (युवा)'\n",
    "assert hi_json['<a class=\"\" href=\"/\">Click Here</a> to go back to home page'] == 'अपने होम पेज पर जाने के लिए <a class=\"\" href=\"/\">यहाँ क्लिक</a> करें'\n",
    "assert hi_json['By proceeding ahead you agree to the <a href=\"../terms-and-conditions.html\" target=\"_blank\"> Terms and Conditions</a>'] == 'आगे बढ़ने का मतलब है कि आप इन <a href=\"../terms-and-conditions.html\" target=\"_blank\"> नियमों और शर्तों</a> से सहमत हैं'\n",
    "assert hi_json['By proceeding ahead you agree to the <a href=\"./terms-and-conditions.html\" target=\"_blank\"> Terms and Conditions</a>'] == 'आगे बढ़ने का मतलब है कि आप इन <a href=\"./terms-and-conditions.html\" target=\"_blank\"> नियमों और शर्तों</a> से सहमत हैं'\n",
    "assert hi_json['Contributions'] == 'योगदान'\n",
    "assert hi_json['Female'] == 'महिला'\n",
    "assert hi_json['Language'] == 'हिंदी'\n",
    "assert hi_json['Get started by clicking on <b>Record</b> button'] == \"'रिकॉर्ड करें' बटन पर क्लिक करके शुरू करें\"\n",
    "assert hi_json['TO'] == 'इस भाषा में'\n",
    "assert hi_json['Validate More'] == 'और सत्यापन करें'\n",
    "assert hi_json['You’ve earned a <span id=\"current_badge_name_1\"></span> Bhasha Samarthak Badge by validating <span id=\"current_badge_count\"></span> Images.'] == 'आपने <span id=\"current_badge_count\"></span> इमेज को सत्यापित करके एक <span id=\"current_badge_name_1\"></span> भाषा समर्थक बैज जीता है।'\n",
    "assert hi_json['image label(s) validated'] == 'इमेज लेबल सत्यापित किए गए'\n",
    "assert hi_json['Your next goal is to reach <span id=\"next_badge_count\"></span> images to earn your <span id=\"next_badge_name_1\"></span> Bhasha Samarthak Badge.'] == 'अपना <span id=\"next_badge_name_1\"></span> भाषा समर्थक बैज जीतने के लिए आपका अगला लक्ष्य <span id=\"next_badge_count\"></span> इमेज तक पहुंचना है।'\n",
    "\n",
    "assert hi_json['social sharing text with rank'] == 'मैंने https://bhashini.gov.in/bhashadaan पर भारत के लिए ओपन लैंग्वेज रिपॉज़िटरी बनाने में योगदान किया है। आप और मैं हमारी आवाज़ों का योगदान करके इस पहल में काफ़ी फ़र्क डाल सकते हैं जिससे मशीन को हमारी भाषा सीखने में मदद मिलती है। \\\\\"बोलो इंडिया\\\\\" पर हमारी <x> भाषा का रैंक <y> है। अपनी भाषा को सशक्त बनाने में अपना योगदान देना चाहेंगे?'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
