{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59360615",
   "metadata": {},
   "source": [
    "# Generate Delta Excel Files using JSON as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d3114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1abfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_column(dataframe, column_name, index):\n",
    "    popped_column = dataframe.pop(column_name)\n",
    "    dataframe.insert(index, column_name, popped_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea91fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file_path):\n",
    "    with open(json_file_path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1838dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_en_key_values(input_base_path):\n",
    "    language_code = 'en'\n",
    "    input_json_path = '{base_path}/{language}.json'.format(base_path=input_base_path, language=language_code)\n",
    "    json_data = read_json(input_json_path)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84504cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_for_data(key, processed_text, replacement_mapping_dict):\n",
    "    out_dict = {}\n",
    "    out_dict[\"Key\"] = key\n",
    "    out_dict[\"English copy\"] = [processed_text]\n",
    "    for replacement in sorted (replacement_mapping_dict.keys()):\n",
    "        out_dict[replacement] = [replacement_mapping_dict[replacement]]\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d0d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_html_tag(tag):\n",
    "    text_extraction_regex = r\"<(\\S*?)[^>]*>(.*?)<\\/\\1>\"\n",
    "    out_tag = tag\n",
    "    matches = re.finditer(text_extraction_regex, out_tag, re.MULTILINE)\n",
    "    string_matches = set()\n",
    "    for match in matches:\n",
    "        match_group_length = len(match.groups())\n",
    "        if match_group_length>1 and len(match.group(2)) != 0:\n",
    "            string_matches.add(match.group(2).strip())\n",
    "    return string_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3511f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_replace_tags(text, allowed_replacements):\n",
    "    tag_identification_regex = r\"<(\\S*?)[^>]*>.*?<\\/\\1>|<.*?\\/>\"\n",
    "    out_txt = text\n",
    "    matched_tags = re.finditer(tag_identification_regex, out_txt, re.MULTILINE)\n",
    "    replacement_identifier_index = 0\n",
    "    replacement_mapping_dict = {}\n",
    "    for match in matched_tags:\n",
    "        matched_tag = match.group()\n",
    "        if \"<b>\" in matched_tag:\n",
    "            continue\n",
    "        elif \"<a\" in matched_tag:\n",
    "            attributes_part_string = matched_tag[matched_tag.find('<a')+2: matched_tag.find('>')]\n",
    "            replacement_mapping_dict['a-tag-replacement'] = attributes_part_string\n",
    "            matched_tag_replacement = matched_tag.replace(attributes_part_string,\"\")\n",
    "            out_txt = out_txt.replace(matched_tag, matched_tag_replacement)\n",
    "        else:\n",
    "            replacement = allowed_replacements[replacement_identifier_index]\n",
    "            replacement_mapping_dict[replacement] = matched_tag\n",
    "            replacement_identifier_index+=1\n",
    "            out_txt = out_txt.replace(matched_tag, '<{}>'.format(replacement))\n",
    "    return out_txt , replacement_mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1493607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_without_translation(language_name, json_data, allowed_replacements, en_data):\n",
    "    language_df = pd.DataFrame([], columns=[])\n",
    "    keys_without_translation = find_keys_without_translation(json_data)\n",
    "        \n",
    "    for key in keys_without_translation:\n",
    "        en_value = en_data[key]\n",
    "        processed_text, replacement_mapping_dict = extract_and_replace_tags(en_value, allowed_replacements)\n",
    "        data_dict = get_dict_for_data(key, processed_text, replacement_mapping_dict)\n",
    "        try:\n",
    "            tmp_df = pd.DataFrame.from_dict(data_dict, orient='columns')\n",
    "            language_df = language_df.append(tmp_df, ignore_index=True)\n",
    "        except Exception as e:\n",
    "            print(e, \"\\n\", data_dict, \"\\n\\n\")\n",
    "    language_df[language_name] = \"\"\n",
    "    move_column(language_df, language_name,1)        \n",
    "    return language_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4286e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keys_without_translation(json_data):\n",
    "    keys_without_translation = []\n",
    "    for key, value in json_data.items():\n",
    "        if key == value and value:\n",
    "            keys_without_translation.append(key)\n",
    "    return keys_without_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f81fd495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_delta(languages, input_base_path, meta_out_base_path, sme_out_base_path):\n",
    "    os.makedirs(meta_out_base_path, exist_ok=True)\n",
    "    os.makedirs(sme_out_base_path, exist_ok=True)\n",
    "\n",
    "    allowed_replacements = [\"u\",\"v\",\"w\",\"x\", \"y\", \"z\"]\n",
    "    en_data = load_en_key_values(input_base_path)\n",
    "\n",
    "    for language_code, language_name in languages:\n",
    "        input_json_path = '{base_path}/{language}.json'.format(base_path=input_base_path, language=language_code)\n",
    "        json_data = read_json(input_json_path)\n",
    "\n",
    "        language_df = get_data_without_translation(language_name, json_data, allowed_replacements, en_data)\n",
    "\n",
    "        output_excel_path = '{base_path}/{language}.xlsx'.format(base_path=meta_out_base_path, language=language_code)\n",
    "        language_df.to_excel(output_excel_path, index = False)\n",
    "        output_sme_excel_path = '{base_path}/{language}.xlsx'.format(base_path=sme_out_base_path, language=language_code)\n",
    "        to_smes = language_df[[\"English copy\", language_name]]\n",
    "        to_smes = to_smes.drop_duplicates(subset=[\"English copy\"], keep=\"first\")\n",
    "        to_smes.to_excel(output_sme_excel_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8735a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fil in os.listdir(sme_out_base_path):\n",
    "#     base = './../locale_generation/input_excel_files/{}'.format(fil.replace('.xlsx',''))\n",
    "#     os.makedirs(base, exist_ok=True)\n",
    "#     os.system('cp {} {}'.format(sme_out_base_path+\"/\"+fil, base+\"/\"+fil))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44694a5e",
   "metadata": {},
   "source": [
    "## MAIN CELL TO GENERATE DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f94b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGES = {'hi': \"Hindi\",'gu': \"Gujarati\",'as': \"Assamese\",'bn':'Bengali','ta':\"Tamil\",\n",
    "             'te':\"Telugu\",'mr':\"Marathi\",'pa':\"Punjabi\",'ml':\"Malayalam\",'or':\"Odia\",'kn':\"Kannada\"}\n",
    "example = '''\n",
    "        Example commands:\n",
    "        \n",
    "        For specific languages:\n",
    "            python DeltaGenerator.py -i ./../../../crowdsource-ui/locales -o . -l gu pa\n",
    "        \n",
    "        For all languages:\n",
    "            python DeltaGenerator.py -i ./../../../crowdsource-ui/locales -o . -a\n",
    "    '''\n",
    "\n",
    "parser = argparse.ArgumentParser(epilog=example,\n",
    "                                 formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "group = parser.add_mutually_exclusive_group(required=True)\n",
    "group.add_argument(\"-a\", \"--all-languages\", action=\"store_true\", help = \"Generate delta for all languages\")\n",
    "group.add_argument(\"-l\", \"--languages\", nargs=\"+\", help = \"Generate delta for the languages mentioned by language codes(space separated)\", choices=list(LANGUAGES.keys()))\n",
    "parser.add_argument(\"-i\", \"--input-folder-path\", required=True, help = \"Input folder path with json files present\")\n",
    "parser.add_argument(\"-o\", \"--output-folder-path\", required=True, help = \"Output folder path where excels are generated\")\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"-i ./../../../crowdsource-ui/locales -o . -a\".split())\n",
    "languages = {}\n",
    "if args.all_languages:\n",
    "    languages = LANGUAGES.copy()\n",
    "else:\n",
    "    language_codes = args.languages\n",
    "    for code in language_codes:\n",
    "        languages[code] = LANGUAGES[code]\n",
    "\n",
    "input_base_path = args.input_folder_path\n",
    "output_base_path = args.output_folder_path\n",
    "        \n",
    "meta_out_base_path = os.path.join(output_base_path, 'out-meta/')\n",
    "sme_out_base_path = os.path.join(output_base_path, 'out-sme/')\n",
    "\n",
    "gen_delta(languages.items(), input_base_path, meta_out_base_path, sme_out_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6e30e",
   "metadata": {},
   "source": [
    "## TESTS TO VERIFY DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7621ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_as_df(file):\n",
    "    excel = pd.ExcelFile(file)\n",
    "    for sheet_name in excel.sheet_names:\n",
    "        sheet = excel.parse(sheet_name = sheet_name, header=0)\n",
    "        return sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff9559",
   "metadata": {},
   "source": [
    "##### Multiple test cases with success scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2b72ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [('hi', \"Hindi\")]\n",
    "input_base_path = './../test-data/proper-success-case-check'\n",
    "meta_out_base_path = input_base_path+ \"/out-meta\"\n",
    "sme_out_base_path = input_base_path+ \"/out-sme\"\n",
    "\n",
    "gen_delta(languages, input_base_path, meta_out_base_path, sme_out_base_path)\n",
    "\n",
    "meta_xl = read_excel_as_df(meta_out_base_path+'/hi.xlsx')\n",
    "sme_xl = read_excel_as_df(sme_out_base_path+'/hi.xlsx')\n",
    "\n",
    "assert meta_xl[\"English copy\"].count() == 15\n",
    "assert len(meta_xl.columns) == 6\n",
    "assert sme_xl[\"English copy\"].count() == 14\n",
    "assert len(sme_xl.columns) == 2\n",
    "\n",
    "\n",
    "assert meta_xl['English copy'][2] == '<a>Click Here</a> to go back to home page'\n",
    "assert meta_xl['a-tag-replacement'][2] == ' class=\"\" href=\"/\"'\n",
    "\n",
    "assert meta_xl['English copy'][3] == 'By proceeding ahead you agree to the <a> Terms and Conditions</a>'\n",
    "assert meta_xl['a-tag-replacement'][3] == ' href=\"../terms-and-conditions.html\" target=\"_blank\"'\n",
    "\n",
    "assert meta_xl['English copy'][4] == 'By proceeding ahead you agree to the <a> Terms and Conditions</a>'\n",
    "assert meta_xl['a-tag-replacement'][4] == ' href=\"./terms-and-conditions.html\" target=\"_blank\"'\n",
    "\n",
    "\n",
    "assert meta_xl['English copy'][11] == 'Youâ€™ve earned a <u> Bhasha Samarthak Badge by validating <v> Images.'\n",
    "assert meta_xl['u'][11] == '<span id=\"current_badge_name_1\"></span>'\n",
    "assert meta_xl['v'][11] == '<span id=\"current_badge_count\"></span>'\n",
    "\n",
    "\n",
    "assert meta_xl['English copy'][14] == 'Your next goal is to reach <u> images to earn your <v> Bhasha Samarthak Badge.'\n",
    "assert meta_xl['u'][14] == '<span id=\"next_badge_count\"></span>'\n",
    "assert meta_xl['v'][14] == '<span id=\"next_badge_name_1\"></span>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713614a9",
   "metadata": {},
   "source": [
    "###### Fetch only the non-translated keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c750b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [('hi', \"Hindi\")]\n",
    "input_base_path = './../test-data/fetch-only-non-translated'\n",
    "meta_out_base_path = input_base_path+ \"/out-meta\"\n",
    "sme_out_base_path = input_base_path+ \"/out-sme\"\n",
    "\n",
    "gen_delta(languages, input_base_path, meta_out_base_path, sme_out_base_path)\n",
    "\n",
    "meta_xl = read_excel_as_df(meta_out_base_path+'/hi.xlsx')\n",
    "sme_xl = read_excel_as_df(sme_out_base_path+'/hi.xlsx')\n",
    "\n",
    "assert meta_xl[\"English copy\"].count() == 1\n",
    "assert len(meta_xl.columns) == 3\n",
    "assert sme_xl[\"English copy\"].count() == 1\n",
    "assert len(sme_xl.columns) == 2\n",
    "\n",
    "\n",
    "assert meta_xl['English copy'][0] == '(No Username)'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
